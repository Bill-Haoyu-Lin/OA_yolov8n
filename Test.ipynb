{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce156d2",
   "metadata": {},
   "source": [
    "# Object Detection\n",
    "\n",
    "Your task is to train a model to detect Air conditioner, Chair, PersonsSofa\n",
    "Table\n",
    "Tv\n",
    "Window\n",
    ".\n",
    "\n",
    "Along with the notebook, you'll find a dataset consisting of three categories of training, validation, and testing. The dataset cotains labels, as class of an object and its bounding box coordinates.\n",
    "\n",
    "# Deliverables\n",
    "1. Train an object detector using the YOLO V8 model (yolov8n).\n",
    "2. Evaluate the trained model on the provided test set.\n",
    "3. Provide the test statistics and any comments on the approach, the considerations youâ€™ve made, and the results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300d8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5243b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a YOLOv8n model from pretrained weight\n",
    "#load the model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "results = model.train(data=\"./datasets/furniture.yaml\", epochs=200, imgsz=640, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c30ca52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.21 ðŸš€ Python-3.11.9 torch-2.3.0 CPU (Apple M2 Pro)\n",
      "Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/haoyulin/Documents/OA_CVE/datasets/test/labels... 24 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 1711.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /Users/haoyulin/Documents/OA_CVE/datasets/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         24        105      0.719      0.538      0.591      0.351\n",
      "                    AC         24          3      0.447      0.333      0.372     0.0806\n",
      "                 Chair         24         12      0.482      0.312      0.358      0.228\n",
      "                People         24          2          1          0          0          0\n",
      "                  Sofa         24         29      0.726      0.966      0.933      0.622\n",
      "                 Table         24         21      0.768      0.788      0.816      0.505\n",
      "                    Tv         24         15      0.826        0.8      0.848      0.624\n",
      "                Window         24         23      0.785      0.565      0.813      0.395\n",
      "Speed: 2.0ms preprocess, 182.3ms inference, 0.0ms loss, 11.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val10\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0.080552,     0.22841,           0,     0.62184,     0.50542,     0.62404,     0.39479])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(\"runs/detect/train35/weights/best.pt\")\n",
    "\n",
    "validation_results = model.val(data=\"./datasets/furniture.yaml\", imgsz=640, batch=32)\n",
    "validation_results.box.maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917835d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the simpliest approach to train a yolov8n model base on custom dataset\n",
    "# Due to the size limitation of dataset provided, yolov8n will need more than 1500 instances per class for a good performance. \n",
    "# Most Class performance over 70% on mAP50 but none go over for mAP50-95. \n",
    "# Model is not improving after around 150 iteration. \n",
    "# Some fine tune for futrue improvement can be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7dd35ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Iterate through results to gather predictions and true labels\n",
    "for result in results:\n",
    "    # Assuming each result corresponds to one image\n",
    "    for box in result.boxes:\n",
    "        y_true.append(box.cls)\n",
    "        y_pred.append(box.conf.argmax())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
